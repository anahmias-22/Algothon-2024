{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Slack integration, data handling, and machine learning\n",
    "import re\n",
    "import time\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "import cryptpandas as crp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Slack Bot Configuration\n",
    "SLACK_BOT_TOKEN = \"BOT_TOKEN\"  # Replace with your bot token\n",
    "CHANNEL_NAME = \"#the-challenge\"  # Slack channel to monitor\n",
    "AUTHORIZED_USER_ID = \"ID\"  # Authorized user to trigger the bot actions\n",
    "\n",
    "# Initialize Slack WebClient\n",
    "client = WebClient(token=SLACK_BOT_TOKEN)\n",
    "\n",
    "# Function to retrieve the Slack channel ID from the channel name\n",
    "def get_channel_id(channel_name):\n",
    "    try:\n",
    "        response = client.conversations_list()\n",
    "        for channel in response[\"channels\"]:\n",
    "            if channel[\"name\"] == channel_name.lstrip(\"#\"):\n",
    "                return channel[\"id\"]\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error fetching channels: {e.response['error']}\")\n",
    "    return None\n",
    "\n",
    "# Extract file ID and password from Slack message\n",
    "def extract_id_and_password(message):\n",
    "    match = re.search(r\"release_(\\d+)\\.crypt.*?passcode is '(.*?)'\", message)\n",
    "    if match:\n",
    "        file_id = match.group(1)\n",
    "        password = match.group(2)\n",
    "        return file_id, password\n",
    "    return None\n",
    "\n",
    "# Monitor Slack channel for new dataset release messages\n",
    "def monitor_channel(channel_id, latest_timestamp):\n",
    "    datasets = []\n",
    "    try:\n",
    "        response = client.conversations_history(channel=channel_id, oldest=latest_timestamp, limit=100)\n",
    "        for message in reversed(response[\"messages\"]):\n",
    "            if message.get(\"user\") == AUTHORIZED_USER_ID and \"Data has just been released\" in message[\"text\"]:\n",
    "                file_id, password = extract_id_and_password(message[\"text\"])\n",
    "                if file_id and password:\n",
    "                    datasets.append((message[\"ts\"], file_id, password))\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error reading channel history: {e.response['error']}\")\n",
    "    return datasets\n",
    "\n",
    "# Load encrypted dataset using the provided password\n",
    "def load_dataset(file_id, password):\n",
    "    try:\n",
    "        file_name = f\"release_{file_id}.crypt\"\n",
    "        file_path = f\"./{file_name}\"\n",
    "        print(f\"Loading dataset: {file_name}\")\n",
    "        X = crp.read_encrypted(path=file_path, password=password)\n",
    "        print(f\"Dataset loaded successfully. Shape: {X.shape}\")\n",
    "        return X\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create lagged features for time-series prediction\n",
    "def create_lagged_features(series, lag=1):\n",
    "    lagged_data = pd.concat([series.shift(i) for i in range(lag, 0, -1)], axis=1)\n",
    "    lagged_data.columns = [f'lag_{i}' for i in range(lag, 0, -1)]\n",
    "    return lagged_data\n",
    "\n",
    "# Apply linear regression to predict and optimize portfolio\n",
    "def compute_predictions(X):\n",
    "    df = X.copy()\n",
    "    lag = 5\n",
    "    predictions = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        lagged_features = create_lagged_features(df[col], lag)\n",
    "        lagged_features['target'] = df[col]\n",
    "        lagged_features = lagged_features.dropna()\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            lagged_features.drop('target', axis=1),\n",
    "            lagged_features['target'],\n",
    "            test_size=0.2,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        next_input = X_test.iloc[-1:].values\n",
    "        next_prediction = model.predict(next_input)\n",
    "        \n",
    "        predictions[col] = next_prediction[0]\n",
    "\n",
    "    def normalize_positions(pos_dict):\n",
    "        pos = pd.Series(pos_dict).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        abs_sum = pos.abs().sum()\n",
    "        if abs_sum > 0:\n",
    "            pos = pos / abs_sum\n",
    "        pos = pos.clip(-0.1, 0.1)\n",
    "        if pos.abs().sum() > 0:\n",
    "            pos = pos / pos.abs().sum()\n",
    "        return pos\n",
    "\n",
    "    def get_submission_dict(pos_dict, team_name=\"Jean Trading 69\", passcode=\"JeanForTheWin\"):\n",
    "        positions = normalize_positions(pos_dict)\n",
    "        return {**positions.to_dict(), \"team_name\": team_name, \"passcode\": passcode}\n",
    "\n",
    "    return get_submission_dict(predictions)\n",
    "\n",
    "# Automate Google Form submission\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium_stealth import stealth\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "LOGIN_URL = \"https://accounts.google.com/signin\"\n",
    "GOOGLE_FORM_URL = \"https://docs.google.com/forms/d/e/1FAIpQLSeUYMkI5ce18RL2aF5C8I7mPxF7haH23VEVz7PQrvz0Do0NrQ/viewform\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "ua = UserAgent()\n",
    "options.add_argument(f'user-agent={ua.random}')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "stealth(driver, languages=[\"en-US\", \"en\"], vendor=\"Google Inc.\", platform=\"Win32\", webgl_vendor=\"Intel Inc.\", renderer=\"Intel Iris OpenGL Engine\", fix_hairline=True)\n",
    "\n",
    "# Fill and submit Google Form with predictions\n",
    "def submit_to_google_form(submission_dict):\n",
    "    driver.get(GOOGLE_FORM_URL)\n",
    "    textarea = driver.find_element(By.XPATH, \"/html/body/div/div[2]/form/div[2]/div/div[2]/div[2]/div/div/div[2]/div/div[1]/div[2]/textarea\")\n",
    "    textarea.clear()\n",
    "    textarea.send_keys(str(submission_dict).replace(\"'\", '\"'))\n",
    "    print(\"Form filled successfully. Please review and submit manually.\")\n",
    "\n",
    "# Main workflow to coordinate Slack monitoring, prediction, and form submission\n",
    "def main():\n",
    "    print(\"Initializing monitoring...\")\n",
    "    channel_id = get_channel_id(CHANNEL_NAME)\n",
    "    latest_timestamp = \"0\"\n",
    "    processed_datasets = set()\n",
    "\n",
    "    while True:\n",
    "        datasets = monitor_channel(channel_id, latest_timestamp)\n",
    "        for ts, file_id, password in datasets:\n",
    "            if file_id not in processed_datasets:\n",
    "                X = load_dataset(file_id, password)\n",
    "                if X is not None:\n",
    "                    submission = compute_predictions(X)\n",
    "                    submit_to_google_form(submission)\n",
    "                processed_datasets.add(file_id)\n",
    "                latest_timestamp = ts\n",
    "        time.sleep(10)\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
